{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d627e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fc834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel = pd.read_pickle('../../data/trimmed_processed/WELFake.pkl')\n",
    "isot = pd.read_pickle('../../data/trimmed_processed/FAKE-REAL.pkl')\n",
    "ind = pd.read_pickle('../../data/trimmed_processed/Indian.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76dead4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "FAKE    60386\n",
       "REAL    60375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([wel,isot,ind])\n",
    "df.shape\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b9db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text'].astype(str)\n",
    "y = df['label']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x,y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0145d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=25000,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "x_train_idf = tfidf.fit_transform(x_train)\n",
    "x_test_idf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522707d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "clf.fit(x_train_idf,y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ad2d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE     0.5774    0.5734    0.5754     12078\n",
      "        REAL     0.5762    0.5803    0.5783     12075\n",
      "\n",
      "    accuracy                         0.5768     24153\n",
      "   macro avg     0.5768    0.5768    0.5768     24153\n",
      "weighted avg     0.5768    0.5768    0.5768     24153\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d',cmap='Blues', xticklabels=clf.classes_,yticklabels=clf.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60475a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "class FakeNewsModelDiagnostics:\n",
    "    def __init__(self, texts, labels, predictions=None, model=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.model = model\n",
    "    \n",
    "    def dataset_quality_check(self):\n",
    "        \"\"\"Comprehensive dataset quality analysis\"\"\"\n",
    "        print(\"=== DATASET QUALITY ANALYSIS ===\\n\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"Total samples: {len(self.texts):,}\")\n",
    "        print(f\"Unique texts: {len(set(self.texts)):,}\")\n",
    "        print(f\"Duplicate rate: {(1 - len(set(self.texts))/len(self.texts))*100:.2f}%\")\n",
    "        \n",
    "        # Label distribution\n",
    "        label_counts = Counter(self.labels)\n",
    "        print(f\"\\nLabel distribution:\")\n",
    "        for label, count in label_counts.items():\n",
    "            label_name = 'FAKE' if label == 0 else 'REAL'\n",
    "            print(f\"  {label_name}: {count:,} ({count/len(self.labels)*100:.1f}%)\")\n",
    "        \n",
    "        # Text length analysis\n",
    "        word_counts = [len(text.split()) for text in self.texts]\n",
    "        char_counts = [len(text) for text in self.texts]\n",
    "        \n",
    "        print(f\"\\nText length statistics:\")\n",
    "        print(f\"  Word count - Mean: {np.mean(word_counts):.1f}, Median: {np.median(word_counts):.1f}\")\n",
    "        print(f\"  Word count - Min: {np.min(word_counts)}, Max: {np.max(word_counts)}\")\n",
    "        print(f\"  Char count - Mean: {np.mean(char_counts):.1f}, Median: {np.median(char_counts):.1f}\")\n",
    "        \n",
    "        # Identify problematic samples\n",
    "        very_short = sum(1 for wc in word_counts if wc < 10)\n",
    "        very_long = sum(1 for wc in word_counts if wc > 2000)\n",
    "        print(f\"  Very short (<10 words): {very_short} ({very_short/len(self.texts)*100:.2f}%)\")\n",
    "        print(f\"  Very long (>2000 words): {very_long} ({very_long/len(self.texts)*100:.2f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'word_counts': word_counts,\n",
    "            'char_counts': char_counts,\n",
    "            'duplicates': len(self.texts) - len(set(self.texts)),\n",
    "            'very_short': very_short,\n",
    "            'very_long': very_long\n",
    "        }\n",
    "    \n",
    "    def analyze_misclassifications(self):\n",
    "        \"\"\"Analyze patterns in misclassified samples\"\"\"\n",
    "        if self.predictions is None:\n",
    "            print(\"No predictions provided for misclassification analysis\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n=== MISCLASSIFICATION ANALYSIS ===\\n\")\n",
    "        \n",
    "        # Get misclassified indices\n",
    "        wrong_indices = np.where(self.predictions != self.labels)[0]\n",
    "        false_positives = np.where((self.predictions == 1) & (self.labels == 0))[0]  # Predicted REAL, actually FAKE\n",
    "        false_negatives = np.where((self.predictions == 0) & (self.labels == 1))[0]  # Predicted FAKE, actually REAL\n",
    "        \n",
    "        print(f\"Total misclassifications: {len(wrong_indices):,} ({len(wrong_indices)/len(self.labels)*100:.1f}%)\")\n",
    "        print(f\"False Positives: {len(false_positives):,} (Real news classified as fake)\")\n",
    "        print(f\"False Negatives: {len(false_negatives):,} (Fake news classified as real)\")\n",
    "        \n",
    "        # Analyze text characteristics of misclassified samples\n",
    "        def analyze_text_group(indices, group_name):\n",
    "            if len(indices) == 0:\n",
    "                return\n",
    "            \n",
    "            group_texts = [self.texts[i] for i in indices]\n",
    "            word_counts = [len(text.split()) for text in group_texts]\n",
    "            \n",
    "            print(f\"\\n{group_name}:\")\n",
    "            print(f\"  Average length: {np.mean(word_counts):.1f} words\")\n",
    "            print(f\"  Length range: {np.min(word_counts)} - {np.max(word_counts)} words\")\n",
    "            \n",
    "            # Show sample misclassifications\n",
    "            print(f\"  Sample texts:\")\n",
    "            for i in range(min(3, len(indices))):\n",
    "                text_preview = group_texts[i][:200] + \"...\" if len(group_texts[i]) > 200 else group_texts[i]\n",
    "                print(f\"    - {text_preview}\")\n",
    "        \n",
    "        analyze_text_group(false_positives, \"False Positives (Predicted REAL, Actually FAKE)\")\n",
    "        analyze_text_group(false_negatives, \"False Negatives (Predicted FAKE, Actually REAL)\")\n",
    "    \n",
    "    def content_pattern_analysis(self):\n",
    "        \"\"\"Analyze content patterns between fake and real news\"\"\"\n",
    "        print(\"\\n=== CONTENT PATTERN ANALYSIS ===\\n\")\n",
    "        \n",
    "        fake_texts = [self.texts[i] for i, label in enumerate(self.labels) if label == 0]\n",
    "        real_texts = [self.texts[i] for i, label in enumerate(self.labels) if label == 1]\n",
    "        \n",
    "        def analyze_group_patterns(texts, group_name):\n",
    "            print(f\"{group_name} News Patterns:\")\n",
    "            \n",
    "            # Length patterns\n",
    "            word_counts = [len(text.split()) for text in texts]\n",
    "            print(f\"  Average length: {np.mean(word_counts):.1f} words\")\n",
    "            \n",
    "            # Punctuation patterns\n",
    "            exclamation_ratio = np.mean([text.count('!') / max(len(text), 1) for text in texts])\n",
    "            question_ratio = np.mean([text.count('?') / max(len(text), 1) for text in texts])\n",
    "            caps_ratio = np.mean([sum(c.isupper() for c in text) / max(len(text), 1) for text in texts])\n",
    "            \n",
    "            print(f\"  Exclamation ratio: {exclamation_ratio:.4f}\")\n",
    "            print(f\"  Question ratio: {question_ratio:.4f}\")\n",
    "            print(f\"  Capitals ratio: {caps_ratio:.4f}\")\n",
    "            \n",
    "            # Common words\n",
    "            all_words = ' '.join(texts).lower().split()\n",
    "            word_freq = Counter(all_words)\n",
    "            common_words = word_freq.most_common(10)\n",
    "            print(f\"  Most common words: {[word for word, freq in common_words[:5]]}\")\n",
    "            \n",
    "        analyze_group_patterns(fake_texts, \"FAKE\")\n",
    "        print()\n",
    "        analyze_group_patterns(real_texts, \"REAL\")\n",
    "    \n",
    "    def suggest_improvements(self):\n",
    "        \"\"\"Provide targeted improvement suggestions\"\"\"\n",
    "        print(\"\\n=== IMPROVEMENT SUGGESTIONS ===\\n\")\n",
    "        \n",
    "        stats = self.dataset_quality_check()\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        # Data quality issues\n",
    "        if stats['duplicates'] > len(self.texts) * 0.05:\n",
    "            suggestions.append(\"🔍 Remove duplicate articles - they may cause overfitting\")\n",
    "        \n",
    "        if stats['very_short'] > len(self.texts) * 0.05:\n",
    "            suggestions.append(\"📝 Consider removing very short articles (<10 words) - insufficient content for classification\")\n",
    "        \n",
    "        if stats['very_long'] > len(self.texts) * 0.05:\n",
    "            suggestions.append(\"✂️ Consider truncating very long articles or using hierarchical attention\")\n",
    "        \n",
    "        # Performance-based suggestions\n",
    "        suggestions.extend([\n",
    "            \"🧠 Try ensemble methods (Random Forest + XGBoost + Logistic Regression)\",\n",
    "            \"📊 Use TF-IDF with character n-grams (1-4 chars) - captures stylistic differences\",\n",
    "            \"🎯 Add domain-specific features (sensational words, bias indicators, source mentions)\",\n",
    "            \"🔄 Use stratified cross-validation to ensure consistent performance\",\n",
    "            \"⚖️ Consider class weighting if dataset is imbalanced\",\n",
    "            \"🤖 Try pre-trained embeddings (BERT, RoBERTa) for semantic understanding\",\n",
    "            \"🔍 Implement feature selection to reduce noise\",\n",
    "            \"📈 Use learning curves to check for overfitting/underfitting\"\n",
    "        ])\n",
    "        \n",
    "        for i, suggestion in enumerate(suggestions, 1):\n",
    "            print(f\"{i}. {suggestion}\")\n",
    "    \n",
    "    def plot_performance_analysis(self):\n",
    "        \"\"\"Create visualizations for performance analysis\"\"\"\n",
    "        if self.predictions is None:\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(self.labels, self.predictions)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Confusion Matrix')\n",
    "        axes[0,0].set_xlabel('Predicted')\n",
    "        axes[0,0].set_ylabel('Actual')\n",
    "        \n",
    "        # Length distribution by class\n",
    "        fake_lengths = [len(self.texts[i].split()) for i, label in enumerate(self.labels) if label == 0]\n",
    "        real_lengths = [len(self.texts[i].split()) for i, label in enumerate(self.labels) if label == 1]\n",
    "        \n",
    "        axes[0,1].hist([fake_lengths, real_lengths], bins=50, alpha=0.7, label=['Fake', 'Real'])\n",
    "        axes[0,1].set_title('Text Length Distribution by Class')\n",
    "        axes[0,1].set_xlabel('Word Count')\n",
    "        axes[0,1].set_ylabel('Frequency')\n",
    "        axes[0,1].legend()\n",
    "        \n",
    "        # Misclassification length analysis\n",
    "        if self.predictions is not None:\n",
    "            correct_indices = np.where(self.predictions == self.labels)[0]\n",
    "            wrong_indices = np.where(self.predictions != self.labels)[0]\n",
    "            \n",
    "            correct_lengths = [len(self.texts[i].split()) for i in correct_indices]\n",
    "            wrong_lengths = [len(self.texts[i].split()) for i in wrong_indices]\n",
    "            \n",
    "            axes[1,0].hist([correct_lengths, wrong_lengths], bins=50, alpha=0.7, \n",
    "                          label=['Correct', 'Misclassified'])\n",
    "            axes[1,0].set_title('Length Distribution: Correct vs Misclassified')\n",
    "            axes[1,0].set_xlabel('Word Count')\n",
    "            axes[1,0].set_ylabel('Frequency')\n",
    "            axes[1,0].legend()\n",
    "        \n",
    "        # Class distribution\n",
    "        label_counts = Counter(self.labels)\n",
    "        axes[1,1].bar(['Fake', 'Real'], [label_counts[0], label_counts[1]])\n",
    "        axes[1,1].set_title('Class Distribution')\n",
    "        axes[1,1].set_ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ae25a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 TO RUN: Replace the variable names below and execute:\n",
      "results = quick_algorithm_comparison(texts, labels)\n",
      "\n",
      "Make sure your text data variable contains the raw text strings,\n",
      "not the already vectorized features!\n",
      "🔄 Running Algorithm Comparison...\n",
      "================================================================================\n",
      "\n",
      "Testing Logistic Regression...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 324\u001b[39m\n\u001b[32m    321\u001b[39m comparison = AlgorithmComparison(df[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Run the actual comparison (this will take a few minutes)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m results = \u001b[43mcomparison\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompare_algorithms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[32m    327\u001b[39m comparison.print_summary()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mAlgorithmComparison.compare_algorithms\u001b[39m\u001b[34m(self, cv_folds)\u001b[39m\n\u001b[32m     81\u001b[39m start_time = time.time()\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Cross-validation scores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m f1_scores = cross_val_score(\n\u001b[32m     90\u001b[39m     model, \u001b[38;5;28mself\u001b[39m.X_texts, \u001b[38;5;28mself\u001b[39m.y_labels, \n\u001b[32m     91\u001b[39m     cv=skf, scoring=\u001b[33m'\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     92\u001b[39m )\n\u001b[32m     94\u001b[39m training_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kknah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "\n",
    "class AlgorithmComparison:\n",
    "    def __init__(self, X_texts, y_labels, test_size=0.2, random_state=42):\n",
    "        self.X_texts = X_texts\n",
    "        self.y_labels = y_labels\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.results = {}\n",
    "        \n",
    "    def create_models(self):\n",
    "        \"\"\"Create different model pipelines for comparison\"\"\"\n",
    "        \n",
    "        # Common TF-IDF parameters\n",
    "        tfidf_params = {\n",
    "            'ngram_range': (1, 3),\n",
    "            'max_features': 10000,\n",
    "            'min_df': 2,\n",
    "            'max_df': 0.95,\n",
    "            'stop_words': 'english'\n",
    "        }\n",
    "        \n",
    "        models = {\n",
    "            'Logistic Regression': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
    "                ('classifier', LogisticRegression(C=1.0, max_iter=1000, random_state=self.random_state))\n",
    "            ]),\n",
    "            \n",
    "            'SVM Linear': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
    "                ('classifier', SVC(kernel='linear', C=1.0, random_state=self.random_state))\n",
    "            ]),\n",
    "            \n",
    "            'SVM RBF': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=5000, min_df=2, max_df=0.95, stop_words='english')),\n",
    "                ('classifier', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=self.random_state))\n",
    "            ]),\n",
    "            \n",
    "            'Naive Bayes (Multinomial)': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
    "                ('classifier', MultinomialNB(alpha=0.1))\n",
    "            ]),\n",
    "            \n",
    "            'Naive Bayes (Complement)': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
    "                ('classifier', ComplementNB(alpha=0.1))\n",
    "            ]),\n",
    "            \n",
    "            'Random Forest': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=5000, min_df=2, max_df=0.95, stop_words='english')),\n",
    "                ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=self.random_state))\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def compare_algorithms(self, cv_folds=5):\n",
    "        \"\"\"Compare all algorithms using cross-validation\"\"\"\n",
    "        \n",
    "        models = self.create_models()\n",
    "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        print(\"🔄 Running Algorithm Comparison...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nTesting {name}...\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Cross-validation scores\n",
    "            cv_scores = cross_val_score(\n",
    "                model, self.X_texts, self.y_labels, \n",
    "                cv=skf, scoring='accuracy', n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            f1_scores = cross_val_score(\n",
    "                model, self.X_texts, self.y_labels, \n",
    "                cv=skf, scoring='f1_macro', n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            result = {\n",
    "                'Algorithm': name,\n",
    "                'Mean Accuracy': cv_scores.mean(),\n",
    "                'Std Accuracy': cv_scores.std(),\n",
    "                'Mean F1-Score': f1_scores.mean(),\n",
    "                'Std F1-Score': f1_scores.std(),\n",
    "                'Training Time (s)': training_time,\n",
    "                'CV Scores': cv_scores\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"  ✅ Accuracy: {cv_scores.mean():.4f} (±{cv_scores.std()*2:.4f})\")\n",
    "            print(f\"  ✅ F1-Score: {f1_scores.mean():.4f} (±{f1_scores.std()*2:.4f})\")\n",
    "            print(f\"  ⏱️  Time: {training_time:.2f}s\")\n",
    "        \n",
    "        # Sort by accuracy\n",
    "        results.sort(key=lambda x: x['Mean Accuracy'], reverse=True)\n",
    "        \n",
    "        self.results = results\n",
    "        return results\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print a comprehensive summary of results\"\"\"\n",
    "        \n",
    "        if not self.results:\n",
    "            print(\"No results available. Run compare_algorithms() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"🏆 FINAL RANKINGS\" + \"\\n\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                'Rank': i+1,\n",
    "                'Algorithm': result['Algorithm'],\n",
    "                'Accuracy': f\"{result['Mean Accuracy']:.4f} ±{result['Std Accuracy']*2:.4f}\",\n",
    "                'F1-Score': f\"{result['Mean F1-Score']:.4f} ±{result['Std F1-Score']*2:.4f}\",\n",
    "                'Time (s)': f\"{result['Training Time (s)']:.1f}\"\n",
    "            }\n",
    "            for i, result in enumerate(self.results)\n",
    "        ])\n",
    "        \n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Best performer analysis\n",
    "        best = self.results[0]\n",
    "        print(f\"\\n🥇 BEST PERFORMER: {best['Algorithm']}\")\n",
    "        print(f\"   Accuracy: {best['Mean Accuracy']:.4f} (±{best['Std Accuracy']*2:.4f})\")\n",
    "        print(f\"   F1-Score: {best['Mean F1-Score']:.4f} (±{best['Std F1-Score']*2:.4f})\")\n",
    "        \n",
    "        # Improvement analysis\n",
    "        if len(self.results) > 1:\n",
    "            baseline = next((r for r in self.results if 'Logistic' in r['Algorithm']), self.results[-1])\n",
    "            improvement = best['Mean Accuracy'] - baseline['Mean Accuracy']\n",
    "            print(f\"\\n📈 IMPROVEMENT OVER BASELINE:\")\n",
    "            print(f\"   +{improvement:.4f} accuracy (+{improvement*100:.2f}%)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best performing model\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results available. Run compare_algorithms() first.\")\n",
    "            return None\n",
    "        \n",
    "        best_name = self.results[0]['Algorithm']\n",
    "        models = self.create_models()\n",
    "        return models[best_name]\n",
    "    \n",
    "    def detailed_analysis(self, top_n=3):\n",
    "        \"\"\"Provide detailed analysis of top performers\"\"\"\n",
    "        \n",
    "        if not self.results:\n",
    "            print(\"No results available. Run compare_algorithms() first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n🔍 DETAILED ANALYSIS - TOP {top_n} PERFORMERS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, result in enumerate(self.results[:top_n]):\n",
    "            print(f\"\\n{i+1}. {result['Algorithm']}\")\n",
    "            print(f\"   📊 Individual CV Scores: {[f'{score:.4f}' for score in result['CV Scores']]}\")\n",
    "            print(f\"   📈 Best CV Score: {max(result['CV Scores']):.4f}\")\n",
    "            print(f\"   📉 Worst CV Score: {min(result['CV Scores']):.4f}\")\n",
    "            print(f\"   🎯 Consistency: {'High' if result['Std Accuracy'] < 0.01 else 'Medium' if result['Std Accuracy'] < 0.02 else 'Low'}\")\n",
    "            \n",
    "            # Performance insights\n",
    "            if 'SVM' in result['Algorithm']:\n",
    "                print(f\"   💡 Insight: SVM excels with high-dimensional sparse text data\")\n",
    "            elif 'Naive Bayes' in result['Algorithm']:\n",
    "                print(f\"   💡 Insight: Fast and effective for text classification, assumes feature independence\")\n",
    "            elif 'Logistic' in result['Algorithm']:\n",
    "                print(f\"   💡 Insight: Good baseline, interpretable coefficients\")\n",
    "            elif 'Random Forest' in result['Algorithm']:\n",
    "                print(f\"   💡 Insight: Handles feature interactions, less interpretable\")\n",
    "\n",
    "# Quick Algorithm Comparison - Ready to Run\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def quick_algorithm_comparison(texts, labels, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Quick comparison of different algorithms\n",
    "    Replace 'texts' and 'labels' with your actual data variables\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting Quick Algorithm Comparison...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define models to test\n",
    "    models = {\n",
    "        'Logistic Regression': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=10000, stop_words='english')),\n",
    "            ('clf', LogisticRegression(C=1.0, max_iter=1000))\n",
    "        ]),\n",
    "        \n",
    "        'SVM Linear': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1,3), max_features=10000, stop_words='english')),\n",
    "            ('clf', SVC(kernel='linear', C=1.0))\n",
    "        ]),\n",
    "        \n",
    "        'SVM RBF': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=5000, stop_words='english')),\n",
    "            ('clf', SVC(kernel='rbf', C=1.0, gamma='scale'))\n",
    "        ]),\n",
    "        \n",
    "        'Naive Bayes': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=10000, stop_words='english')),\n",
    "            ('clf', MultinomialNB(alpha=0.1))\n",
    "        ]),\n",
    "        \n",
    "        'Random Forest': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1,2), max_features=5000, stop_words='english')),\n",
    "            ('clf', RandomForestClassifier(n_estimators=50, max_depth=10))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n🔄 Testing {name}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Cross-validation\n",
    "            accuracy_scores = cross_val_score(model, texts, labels, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "            f1_scores = cross_val_score(model, texts, labels, cv=skf, scoring='f1_macro', n_jobs=-1)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            results.append({\n",
    "                'Algorithm': name,\n",
    "                'Accuracy': accuracy_scores.mean(),\n",
    "                'Accuracy_Std': accuracy_scores.std(),\n",
    "                'F1_Score': f1_scores.mean(),\n",
    "                'F1_Std': f1_scores.std(),\n",
    "                'Time': elapsed_time\n",
    "            })\n",
    "            \n",
    "            print(f\"   ✅ Accuracy: {accuracy_scores.mean():.4f} (±{accuracy_scores.std()*2:.4f})\")\n",
    "            print(f\"   ✅ F1-Score: {f1_scores.mean():.4f} (±{f1_scores.std()*2:.4f})\")\n",
    "            print(f\"   ⏱️  Time: {elapsed_time:.1f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    results.sort(key=lambda x: x['Accuracy'], reverse=True)\n",
    "    \n",
    "    print(\"\\n\" + \"🏆 FINAL RANKINGS\" + \"\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Rank':<4} {'Algorithm':<18} {'Accuracy':<12} {'F1-Score':<12} {'Time':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1:<4} {result['Algorithm']:<18} \"\n",
    "              f\"{result['Accuracy']:.4f}±{result['Accuracy_Std']*2:.3f} \"\n",
    "              f\"{result['F1_Score']:.4f}±{result['F1_Std']*2:.3f} \"\n",
    "              f\"{result['Time']:.1f}s\")\n",
    "    \n",
    "    if results:\n",
    "        best = results[0]\n",
    "        print(f\"\\n🥇 WINNER: {best['Algorithm']}\")\n",
    "        print(f\"   📈 Accuracy: {best['Accuracy']:.4f}\")\n",
    "        print(f\"   🎯 F1-Score: {best['F1_Score']:.4f}\")\n",
    "        \n",
    "        # Calculate improvement over your current result (57.68%)\n",
    "        current_accuracy = 0.5768  # Your current result\n",
    "        improvement = best['Accuracy'] - current_accuracy\n",
    "        improvement_pct = (improvement / current_accuracy) * 100\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(f\"   🚀 Improvement: +{improvement:.4f} (+{improvement_pct:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Change: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# USAGE:\n",
    "# Replace 'your_texts' and 'your_labels' with your actual variable names\n",
    "# results = quick_algorithm_comparison(your_texts, your_labels)\n",
    "\n",
    "# Example with common variable names:\n",
    "# results = quick_algorithm_comparison(texts, labels)\n",
    "# or\n",
    "# results = quick_algorithm_comparison(X_text, y)\n",
    "\n",
    "print(\"📝 TO RUN: Replace the variable names below and execute:\")\n",
    "print(\"results = quick_algorithm_comparison(texts, labels)\")\n",
    "print(\"\\nMake sure your text data variable contains the raw text strings,\")\n",
    "print(\"not the already vectorized features!\")\n",
    "\n",
    "\n",
    "# Initialize comparison with your data\n",
    "comparison = AlgorithmComparison(df['text'], df['label'])\n",
    "\n",
    "# Run the actual comparison (this will take a few minutes)\n",
    "results = comparison.compare_algorithms(cv_folds=5)\n",
    "\n",
    "# Print the results\n",
    "comparison.print_summary()\n",
    "\n",
    "# Get detailed analysis of top performers\n",
    "comparison.detailed_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b4c3a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 RECOMMENDED: Test SVM first (usually best for text)\n",
      "result = test_single_algorithm(df['text'], df['label'], 'svm')\n",
      "\n",
      "💡 To test all algorithms:\n",
      "results = quick_comparison(df['text'], df['label'])\n",
      "\n",
      "🔧 If you still get memory errors:\n",
      "1. Use a smaller sample: df.sample(n=5000)\n",
      "2. Reduce max_features in TfidfVectorizer\n",
      "3. Use fewer n-grams\n"
     ]
    }
   ],
   "source": [
    "# Simple Algorithm Test - Memory Efficient\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "def test_single_algorithm(texts, labels, algorithm='svm', test_size=0.2):\n",
    "    \"\"\"Test a single algorithm efficiently\"\"\"\n",
    "    \n",
    "    print(f\"🧪 Testing {algorithm.upper()}...\")\n",
    "    print(f\"📊 Dataset size: {len(texts):,} samples\")\n",
    "    \n",
    "    # Split data first to reduce memory usage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=test_size, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    print(f\"📈 Training size: {len(X_train):,}\")\n",
    "    print(f\"🎯 Test size: {len(X_test):,}\")\n",
    "    \n",
    "    # Define model based on algorithm choice\n",
    "    if algorithm.lower() == 'svm':\n",
    "        model = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                ngram_range=(1,3), \n",
    "                max_features=8000,  # Reduced for memory\n",
    "                min_df=3,\n",
    "                max_df=0.95,\n",
    "                stop_words='english'\n",
    "            )),\n",
    "            ('classifier', SVC(kernel='linear', C=1.0))\n",
    "        ])\n",
    "        \n",
    "    elif algorithm.lower() == 'nb':\n",
    "        model = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                ngram_range=(1,2), \n",
    "                max_features=8000,\n",
    "                min_df=3,\n",
    "                max_df=0.95,\n",
    "                stop_words='english'\n",
    "            )),\n",
    "            ('classifier', MultinomialNB(alpha=0.1))\n",
    "        ])\n",
    "        \n",
    "    elif algorithm.lower() == 'lr':\n",
    "        model = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                ngram_range=(1,2), \n",
    "                max_features=8000,\n",
    "                min_df=3,\n",
    "                max_df=0.95,\n",
    "                stop_words='english'\n",
    "            )),\n",
    "            ('classifier', LogisticRegression(C=1.0, max_iter=1000))\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Algorithm must be 'svm', 'nb', or 'lr'\")\n",
    "    \n",
    "    # Train and test\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"🔄 Training...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"🔄 Predicting...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n✅ RESULTS for {algorithm.upper()}:\")\n",
    "    print(f\"   🎯 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   ⏱️  Training time: {training_time:.1f}s\")\n",
    "    \n",
    "    # Compare with your baseline (57.68%)\n",
    "    baseline = 0.5768\n",
    "    improvement = accuracy - baseline\n",
    "    improvement_pct = (improvement / baseline) * 100\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(f\"   📈 Improvement: +{improvement:.4f} (+{improvement_pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   📉 Change: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(f\"\\n📊 Detailed Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['FAKE', 'REAL']))\n",
    "    \n",
    "    return {\n",
    "        'algorithm': algorithm,\n",
    "        'accuracy': accuracy,\n",
    "        'improvement': improvement,\n",
    "        'training_time': training_time,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "def quick_comparison(texts, labels):\n",
    "    \"\"\"Test multiple algorithms one by one to avoid memory issues\"\"\"\n",
    "    \n",
    "    algorithms = ['lr', 'svm', 'nb']\n",
    "    results = []\n",
    "    \n",
    "    print(\"🚀 Quick Algorithm Comparison (Sequential)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        try:\n",
    "            result = test_single_algorithm(texts, labels, algo)\n",
    "            results.append(result)\n",
    "            print(\"\\n\" + \"-\" * 60)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error with {algo}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    if results:\n",
    "        print(\"\\n🏆 SUMMARY:\")\n",
    "        results.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            symbol = \"🥇\" if i == 0 else \"🥈\" if i == 1 else \"🥉\"\n",
    "            print(f\"{symbol} {result['algorithm'].upper()}: {result['accuracy']:.4f} \"\n",
    "                  f\"(+{result['improvement']:.4f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# USAGE EXAMPLES:\n",
    "\n",
    "# Test just SVM (recommended first):\n",
    "print(\"💡 RECOMMENDED: Test SVM first (usually best for text)\")\n",
    "print(\"result = test_single_algorithm(df['text'], df['label'], 'svm')\")\n",
    "\n",
    "# Test all three:\n",
    "print(\"\\n💡 To test all algorithms:\")  \n",
    "print(\"results = quick_comparison(df['text'], df['label'])\")\n",
    "\n",
    "print(\"\\n🔧 If you still get memory errors:\")\n",
    "print(\"1. Use a smaller sample: df.sample(n=5000)\")\n",
    "print(\"2. Reduce max_features in TfidfVectorizer\")\n",
    "print(\"3. Use fewer n-grams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8020c967",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 1: Test SVM first (most likely to improve)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result_svm = test_single_algorithm(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msvm\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Test SVM first (most likely to improve)\n",
    "result_svm = test_single_algorithm(df['text'], df['label'], 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e48a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing SVM...\n",
      "📊 Dataset size: 5,000 samples\n",
      "📈 Training size: 4,000\n",
      "🎯 Test size: 1,000\n",
      "🔄 Training...\n",
      "🔄 Predicting...\n",
      "\n",
      "✅ RESULTS for SVM:\n",
      "   🎯 Accuracy: 0.5890 (58.90%)\n",
      "   ⏱️  Training time: 34.0s\n",
      "   📈 Improvement: +0.0122 (+2.1%)\n",
      "\n",
      "📊 Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.60      0.58      0.59       506\n",
      "        REAL       0.58      0.60      0.59       494\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.59      0.59      0.59      1000\n",
      "weighted avg       0.59      0.59      0.59      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a smaller sample to test\n",
    "sample_df = df.sample(n=5000, random_state=42)\n",
    "result_svm = test_single_algorithm(sample_df['text'], sample_df['label'], 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec203132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Quick Algorithm Comparison (Sequential)\n",
      "============================================================\n",
      "🧪 Testing LR...\n",
      "📊 Dataset size: 120,761 samples\n",
      "📈 Training size: 96,608\n",
      "🎯 Test size: 24,153\n",
      "🔄 Training...\n",
      "🔄 Predicting...\n",
      "\n",
      "✅ RESULTS for LR:\n",
      "   🎯 Accuracy: 0.5978 (59.78%)\n",
      "   ⏱️  Training time: 129.5s\n",
      "   📈 Improvement: +0.0210 (+3.6%)\n",
      "\n",
      "📊 Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.60      0.59      0.60     12078\n",
      "        REAL       0.60      0.60      0.60     12075\n",
      "\n",
      "    accuracy                           0.60     24153\n",
      "   macro avg       0.60      0.60      0.60     24153\n",
      "weighted avg       0.60      0.60      0.60     24153\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "🧪 Testing SVM...\n",
      "📊 Dataset size: 120,761 samples\n",
      "📈 Training size: 96,608\n",
      "🎯 Test size: 24,153\n",
      "🔄 Training...\n"
     ]
    }
   ],
   "source": [
    "# Test all algorithms (one at a time to avoid memory issues)\n",
    "results = quick_comparison(df['text'], df['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
